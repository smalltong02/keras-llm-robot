---
language:
- zh
tags:
- embedding
- text-embedding
library_name: sentence-transformers
---

# ğŸ…œ M3E Models

[m3e-small](https://huggingface.co/moka-ai/m3e-small) | [m3e-base](https://huggingface.co/moka-ai/m3e-base)

M3E æ˜¯ Moka Massive Mixed Embedding çš„ç¼©å†™

- Mokaï¼Œæ­¤æ¨¡å‹ç”± MokaAI è®­ç»ƒï¼Œå¼€æºå’Œè¯„æµ‹ï¼Œè®­ç»ƒè„šæœ¬ä½¿ç”¨ [uniem](https://github.com/wangyuxinwhy/uniem/blob/main/scripts/train_m3e.py) ï¼Œè¯„æµ‹ BenchMark ä½¿ç”¨ [MTEB-zh](https://github.com/wangyuxinwhy/uniem/tree/main/mteb-zh)
- Massiveï¼Œæ­¤æ¨¡å‹é€šè¿‡**åƒä¸‡çº§** (2200w+) çš„ä¸­æ–‡å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
- Mixedï¼Œæ­¤æ¨¡å‹æ”¯æŒä¸­è‹±åŒè¯­çš„åŒè´¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå¼‚è´¨æ–‡æœ¬æ£€ç´¢ç­‰åŠŸèƒ½ï¼Œæœªæ¥è¿˜ä¼šæ”¯æŒä»£ç æ£€ç´¢
- Embeddingï¼Œæ­¤æ¨¡å‹æ˜¯æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œå¯ä»¥å°†è‡ªç„¶è¯­è¨€è½¬æ¢æˆç¨ å¯†çš„å‘é‡

## ğŸ†• æ›´æ–°è¯´æ˜

- 2023.06.24ï¼Œæ·»åŠ å¾®è°ƒ M3E çš„æ•™ç¨‹ [notebook](https://github.com/wangyuxinwhy/uniem/blob/main/examples/finetune.ipynb)ï¼Œå‡ è¡Œä»£ç ï¼Œæ›´ä½³é€‚é…ï¼<a target="_blank" href="https://colab.research.google.com/github/wangyuxinwhy/uniem/blob/main/examples/finetune.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
- 2023.06.14ï¼Œæ·»åŠ äº†ä¸‰ä¸ªä¸­æ–‡å¼€æºæ–‡æœ¬åµŒå…¥æ¨¡å‹åˆ°è¯„æµ‹ä¸­ï¼ŒåŒ…æ‹¬ UER, ErLangShen, DMetaSoul
- 2023.06.08ï¼Œæ·»åŠ æ£€ç´¢ä»»åŠ¡çš„è¯„æµ‹ç»“æœï¼Œåœ¨ T2Ranking 1W ä¸­æ–‡æ•°æ®é›†ä¸Šï¼Œm3e-base åœ¨ ndcg@10 ä¸Šè¾¾åˆ°äº† 0.8004ï¼Œè¶…è¿‡äº† openai-ada-002 çš„ 0.7786
- 2023.06.07ï¼Œæ·»åŠ æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„è¯„æµ‹ç»“æœï¼Œåœ¨ 6 ç§æ–‡æœ¬åˆ†ç±»æ•°æ®é›†ä¸Šï¼Œm3e-base åœ¨ accuracy ä¸Šè¾¾åˆ°äº† 0.6157ï¼Œè¶…è¿‡äº† openai-ada-002 çš„ 0.5956

## âš–ï¸ æ¨¡å‹å¯¹æ¯”

|           | å‚æ•°æ•°é‡ | ç»´åº¦ | ä¸­æ–‡ | è‹±æ–‡ | s2s | s2p | s2c | å¼€æº | å…¼å®¹æ€§ | s2s Acc | s2p ndcg@10 |
| --------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ---- | ---------- | ------------ | -------- |
| m3e-small | 24M      | 512      | æ˜¯       | å¦       | æ˜¯       | å¦       | å¦       | æ˜¯   | ä¼˜         | 0.5834       | 0.7262   |
| m3e-base  | 110M     | 768      | æ˜¯       | æ˜¯       | æ˜¯       | æ˜¯       | å¦       | æ˜¯   | ä¼˜         | **0.6157**       | **0.8004**   |
| text2vec  | 110M     | 768      | æ˜¯       | å¦       | æ˜¯       | å¦       | å¦       | æ˜¯   | ä¼˜         | 0.5755       | 0.6346   |
| openai-ada-002    | æœªçŸ¥     | 1536     | æ˜¯       | æ˜¯       | æ˜¯       | æ˜¯       | æ˜¯       | å¦   | ä¼˜         | 0.5956       | 0.7786   |

è¯´æ˜ï¼š
- s2s, å³ sentence to sentence ï¼Œä»£è¡¨äº†åŒè´¨æ–‡æœ¬ä¹‹é—´çš„åµŒå…¥èƒ½åŠ›ï¼Œé€‚ç”¨ä»»åŠ¡ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦ï¼Œé‡å¤é—®é¢˜æ£€æµ‹ï¼Œæ–‡æœ¬åˆ†ç±»ç­‰
- s2p, å³ sentence to passage ï¼Œä»£è¡¨äº†å¼‚è´¨æ–‡æœ¬ä¹‹é—´çš„åµŒå…¥èƒ½åŠ›ï¼Œé€‚ç”¨ä»»åŠ¡ï¼šæ–‡æœ¬æ£€ç´¢ï¼ŒGPT è®°å¿†æ¨¡å—ç­‰
- s2c, å³ sentence to code ï¼Œä»£è¡¨äº†è‡ªç„¶è¯­è¨€å’Œç¨‹åºè¯­è¨€ä¹‹é—´çš„åµŒå…¥èƒ½åŠ›ï¼Œé€‚ç”¨ä»»åŠ¡ï¼šä»£ç æ£€ç´¢
- å…¼å®¹æ€§ï¼Œä»£è¡¨äº†æ¨¡å‹åœ¨å¼€æºç¤¾åŒºä¸­å„ç§é¡¹ç›®è¢«æ”¯æŒçš„ç¨‹åº¦ï¼Œç”±äº m3e å’Œ text2vec éƒ½å¯ä»¥ç›´æ¥é€šè¿‡ sentence-transformers ç›´æ¥ä½¿ç”¨ï¼Œæ‰€ä»¥å’Œ openai åœ¨ç¤¾åŒºçš„æ”¯æŒåº¦ä¸Šç›¸å½“
- ACC & ndcg@10ï¼Œè¯¦æƒ…è§ä¸‹æ–¹çš„è¯„æµ‹

Tips:
- ä½¿ç”¨åœºæ™¯ä¸»è¦æ˜¯ä¸­æ–‡ï¼Œå°‘é‡è‹±æ–‡çš„æƒ…å†µï¼Œå»ºè®®ä½¿ç”¨ m3e ç³»åˆ—çš„æ¨¡å‹
- å¤šè¯­è¨€ä½¿ç”¨åœºæ™¯ï¼Œå¹¶ä¸”ä¸ä»‹æ„æ•°æ®éšç§çš„è¯ï¼Œæˆ‘å»ºè®®ä½¿ç”¨ openai text-embedding-ada-002
- ä»£ç æ£€ç´¢åœºæ™¯ï¼Œæ¨èä½¿ç”¨ openai text-embedding-ada-002
- æ–‡æœ¬æ£€ç´¢åœºæ™¯ï¼Œè¯·ä½¿ç”¨å…·å¤‡æ–‡æœ¬æ£€ç´¢èƒ½åŠ›çš„æ¨¡å‹ï¼Œåªåœ¨ S2S ä¸Šè®­ç»ƒçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œæ²¡æœ‰åŠæ³•å®Œæˆæ–‡æœ¬æ£€ç´¢ä»»åŠ¡

## ğŸ”§ ä½¿ç”¨ M3E

æ‚¨éœ€è¦å…ˆå®‰è£… sentence-transformers

```bash
pip install -U sentence-transformers
```

å®‰è£…å®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç æ¥ä½¿ç”¨ M3E Models

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('moka-ai/m3e-base')

#Our sentences we like to encode
sentences = [
    '* Moka æ­¤æ–‡æœ¬åµŒå…¥æ¨¡å‹ç”± MokaAI è®­ç»ƒå¹¶å¼€æºï¼Œè®­ç»ƒè„šæœ¬ä½¿ç”¨ uniem',
    '* Massive æ­¤æ–‡æœ¬åµŒå…¥æ¨¡å‹é€šè¿‡**åƒä¸‡çº§**çš„ä¸­æ–‡å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒ',
    '* Mixed æ­¤æ–‡æœ¬åµŒå…¥æ¨¡å‹æ”¯æŒä¸­è‹±åŒè¯­çš„åŒè´¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå¼‚è´¨æ–‡æœ¬æ£€ç´¢ç­‰åŠŸèƒ½ï¼Œæœªæ¥è¿˜ä¼šæ”¯æŒä»£ç æ£€ç´¢ï¼ŒALL in one'
]

#Sentences are encoded by calling model.encode()
embeddings = model.encode(sentences)

#Print the embeddings
for sentence, embedding in zip(sentences, embeddings):
    print("Sentence:", sentence)
    print("Embedding:", embedding)
    print("")
```


M3E ç³»åˆ—çš„æ‰€æœ‰æ¨¡å‹åœ¨è®¾è®¡çš„æ—¶å€™å°±è€ƒè™‘åˆ°å®Œå…¨å…¼å®¹ [sentence-transformers](https://www.sbert.net/) ï¼Œæ‰€ä»¥ä½ å¯ä»¥é€šè¿‡**æ›¿æ¢åç§°å­—ç¬¦ä¸²**çš„æ–¹å¼åœ¨æ‰€æœ‰æ”¯æŒ sentence-transformers çš„é¡¹ç›®ä¸­**æ— ç¼**ä½¿ç”¨ M3E Modelsï¼Œæ¯”å¦‚ [chroma](https://docs.trychroma.com/getting-started), [guidance](https://github.com/microsoft/guidance), [semantic-kernel](https://github.com/microsoft/semantic-kernel) ã€‚

## ğŸ¨ å¾®è°ƒæ¨¡å‹

`uniem` æä¾›äº†éå¸¸æ˜“ç”¨çš„ finetune æ¥å£ï¼Œå‡ è¡Œä»£ç ï¼Œå³åˆ»é€‚é…ï¼

```python
from datasets import load_dataset

from uniem.finetuner import FineTuner

dataset = load_dataset('shibing624/nli_zh', 'STS-B')
# æŒ‡å®šè®­ç»ƒçš„æ¨¡å‹ä¸º m3e-small
finetuner = FineTuner.from_pretrained('moka-ai/m3e-small', dataset=dataset)
finetuner.run(epochs=1)
```

è¯¦è§ [uniem å¾®è°ƒæ•™ç¨‹](https://github.com/wangyuxinwhy/uniem/blob/main/examples/finetune.ipynb)

<a target="_blank" href="https://colab.research.google.com/github/wangyuxinwhy/uniem/blob/main/examples/finetune.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

## â¿ è®­ç»ƒæ–¹æ¡ˆ

M3E ä½¿ç”¨ in-batch è´Ÿé‡‡æ ·çš„å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼åœ¨å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä¸ºäº†ä¿è¯ in-batch è´Ÿé‡‡æ ·çš„æ•ˆæœï¼Œæˆ‘ä»¬ä½¿ç”¨ A100 80G æ¥æœ€å¤§åŒ– batch-sizeï¼Œå¹¶åœ¨å…±è®¡ 2200W+ çš„å¥å¯¹æ•°æ®é›†ä¸Šè®­ç»ƒäº† 1 epochã€‚è®­ç»ƒè„šæœ¬ä½¿ç”¨ [uniem](https://github.com/wangyuxinwhy/uniem/blob/main/scripts/train_m3e.py)ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹å…·ä½“ç»†èŠ‚ã€‚

## ğŸŒŸ ç‰¹æ€§

- ä¸­æ–‡è®­ç»ƒé›†ï¼ŒM3E åœ¨å¤§è§„æ¨¡å¥å¯¹æ•°æ®é›†ä¸Šçš„è®­ç»ƒï¼ŒåŒ…å«ä¸­æ–‡ç™¾ç§‘ï¼Œé‡‘èï¼ŒåŒ»ç–—ï¼Œæ³•å¾‹ï¼Œæ–°é—»ï¼Œå­¦æœ¯ç­‰å¤šä¸ªé¢†åŸŸå…±è®¡ 2200W å¥å¯¹æ ·æœ¬ï¼Œæ•°æ®é›†è¯¦è§ [M3E æ•°æ®é›†](#M3Eæ•°æ®é›†)
- è‹±æ–‡è®­ç»ƒé›†ï¼ŒM3E ä½¿ç”¨ MEDI 145W è‹±æ–‡ä¸‰å…ƒç»„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œæ•°æ®é›†è¯¦è§ [MEDI æ•°æ®é›†](https://drive.google.com/file/d/1vZ5c2oJNonGOvXzppNg5mHz24O6jcc52/view)ï¼Œæ­¤æ•°æ®é›†ç”± [instructor team](https://github.com/HKUNLP/instructor-embedding) æä¾›
- æŒ‡ä»¤æ•°æ®é›†ï¼ŒM3E ä½¿ç”¨äº† 300W + çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œè¿™ä½¿å¾— M3E å¯¹æ–‡æœ¬ç¼–ç çš„æ—¶å€™å¯ä»¥éµä»æŒ‡ä»¤ï¼Œè¿™éƒ¨åˆ†çš„å·¥ä½œä¸»è¦è¢«å¯å‘äº [instructor-embedding](https://github.com/HKUNLP/instructor-embedding)
- åŸºç¡€æ¨¡å‹ï¼ŒM3E ä½¿ç”¨ hfl å®éªŒå®¤çš„ [Roberta](https://huggingface.co/hfl/chinese-roberta-wwm-ext) ç³»åˆ—æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œç›®å‰æä¾›  small å’Œ  base ä¸¤ä¸ªç‰ˆæœ¬ï¼Œå¤§å®¶åˆ™éœ€é€‰ç”¨
- ALL IN ONEï¼ŒM3E æ—¨åœ¨æä¾›ä¸€ä¸ª ALL IN ONE çš„æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œä¸ä»…æ”¯æŒåŒè´¨å¥å­ç›¸ä¼¼åº¦åˆ¤æ–­ï¼Œè¿˜æ”¯æŒå¼‚è´¨æ–‡æœ¬æ£€ç´¢ï¼Œä½ åªéœ€è¦ä¸€ä¸ªæ¨¡å‹å°±å¯ä»¥è¦†ç›–å…¨éƒ¨çš„åº”ç”¨åœºæ™¯ï¼Œæœªæ¥è¿˜ä¼šæ”¯æŒä»£ç æ£€ç´¢

## ğŸ’¯ MTEB-zh è¯„æµ‹

- è¯„æµ‹æ¨¡å‹ï¼Œ[text2vec](https://github.com/shibing624/text2vec), m3e-base, m3e-small, openai text-embedding-ada-002, [DMetaSoul](https://huggingface.co/DMetaSoul/sbert-chinese-general-v2), [UER](https://huggingface.co/uer/sbert-base-chinese-nli), [ErLangShen](https://huggingface.co/IDEA-CCNL/Erlangshen-SimCSE-110M-Chinese)
- è¯„æµ‹è„šæœ¬ï¼Œå…·ä½“å‚è€ƒ [MTEB-zh] (https://github.com/wangyuxinwhy/uniem/blob/main/mteb-zh)

### æ–‡æœ¬åˆ†ç±»

- æ•°æ®é›†é€‰æ‹©ï¼Œé€‰æ‹©å¼€æºåœ¨ HuggingFace ä¸Šçš„ 6 ç§æ–‡æœ¬åˆ†ç±»æ•°æ®é›†ï¼ŒåŒ…æ‹¬æ–°é—»ã€ç”µå•†è¯„è®ºã€è‚¡ç¥¨è¯„è®ºã€é•¿æ–‡æœ¬ç­‰
- è¯„æµ‹æ–¹å¼ï¼Œä½¿ç”¨ MTEB çš„æ–¹å¼è¿›è¡Œè¯„æµ‹ï¼ŒæŠ¥å‘Š Accuracyã€‚

|                   | text2vec | m3e-small | m3e-base | openai | DMetaSoul   | uer     | erlangshen  |
| ----------------- | -------- | --------- | -------- | ------ | ----------- | ------- | ----------- |
| TNews             | 0.43     | 0.4443    | **0.4827**   | 0.4594 | 0.3084      | 0.3539  | 0.4361      |
| JDIphone          | 0.8214   | 0.8293    | **0.8533**   | 0.746  | 0.7972      | 0.8283  | 0.8356      |
| GubaEastmony      | 0.7472   | 0.712     | 0.7621   | 0.7574 | 0.735       | 0.7534  | **0.7787**      |
| TYQSentiment      | 0.6099   | 0.6596    | **0.7188**   | 0.68   | 0.6437      | 0.6662  | 0.6444      |
| StockComSentiment | 0.4307   | 0.4291    | 0.4363   | **0.4819** | 0.4309      | 0.4555  | 0.4482      |
| IFlyTek           | 0.414    | 0.4263    | 0.4409   | **0.4486** | 0.3969      | 0.3762  | 0.4241      |
| Average           | 0.5755   | 0.5834    | **0.6157**   | 0.5956 | 0.552016667 | 0.57225 | 0.594516667 |

### æ£€ç´¢æ’åº

#### T2Ranking 1W

- æ•°æ®é›†é€‰æ‹©ï¼Œä½¿ç”¨ [T2Ranking](https://github.com/THUIR/T2Ranking/tree/main) æ•°æ®é›†ï¼Œç”±äº T2Ranking çš„æ•°æ®é›†å¤ªå¤§ï¼Œopenai è¯„æµ‹èµ·æ¥çš„æ—¶é—´æˆæœ¬å’Œ api è´¹ç”¨æœ‰äº›é«˜ï¼Œæ‰€ä»¥æˆ‘ä»¬åªé€‰æ‹©äº† T2Ranking ä¸­çš„å‰ 10000 ç¯‡æ–‡ç« 
- è¯„æµ‹æ–¹å¼ï¼Œä½¿ç”¨ MTEB çš„æ–¹å¼è¿›è¡Œè¯„æµ‹ï¼ŒæŠ¥å‘Š map@1, map@10, mrr@1, mrr@10, ndcg@1, ndcg@10
- æ³¨æ„ï¼ä»å®éªŒç»“æœå’Œè®­ç»ƒæ–¹å¼æ¥çœ‹ï¼Œé™¤äº† M3E æ¨¡å‹å’Œ openai æ¨¡å‹å¤–ï¼Œå…¶ä½™æ¨¡å‹éƒ½æ²¡æœ‰åšæ£€ç´¢ä»»åŠ¡çš„è®­ç»ƒï¼Œæ‰€ä»¥ç»“æœä»…ä¾›å‚è€ƒã€‚

|         | text2vec | openai-ada-002 | m3e-small | m3e-base | DMetaSoul | uer     | erlangshen |
| ------- | -------- | -------------- | --------- | -------- | --------- | ------- | ---------- |
| map@1   | 0.4684   | 0.6133         | 0.5574    | **0.626**    | 0.25203   | 0.08647 | 0.25394    |
| map@10  | 0.5877   | 0.7423         | 0.6878    | **0.7656**   | 0.33312   | 0.13008 | 0.34714    |
| mrr@1   | 0.5345   | 0.6931         | 0.6324    | **0.7047**   | 0.29258   | 0.10067 | 0.29447    |
| mrr@10  | 0.6217   | 0.7668         | 0.712     | **0.7841**   | 0.36287   | 0.14516 | 0.3751     |
| ndcg@1  | 0.5207   | 0.6764         | 0.6159    | **0.6881**   | 0.28358   | 0.09748 | 0.28578    |
| ndcg@10 | 0.6346   | 0.7786         | 0.7262    | **0.8004**   | 0.37468   | 0.15783 | 0.39329    |

#### T2Ranking

- æ•°æ®é›†é€‰æ‹©ï¼Œä½¿ç”¨ T2Rankingï¼Œåˆ¨é™¤ openai-ada-002 æ¨¡å‹åï¼Œæˆ‘ä»¬å¯¹å‰©ä½™çš„ä¸‰ä¸ªæ¨¡å‹ï¼Œè¿›è¡Œ T2Ranking 10W å’Œ T2Ranking 50W çš„è¯„æµ‹ã€‚ï¼ˆT2Ranking è¯„æµ‹å¤ªè€—å†…å­˜äº†... 128G éƒ½ä¸è¡Œï¼‰
- è¯„æµ‹æ–¹å¼ï¼Œä½¿ç”¨ MTEB çš„æ–¹å¼è¿›è¡Œè¯„æµ‹ï¼ŒæŠ¥å‘Š ndcg@10

|         | text2vec | m3e-small | m3e-base |
| ------- | -------- | --------- | -------- |
| t2r-1w  | 0.6346   | 0.72621   | **0.8004**   |
| t2r-10w | 0.44644  | 0.5251    | **0.6263**   |
| t2r-50w | 0.33482  | 0.38626   | **0.47364**  |

è¯´æ˜ï¼š
- æ£€ç´¢æ’åºå¯¹äº text2vec å¹¶ä¸å…¬å¹³ï¼Œå› ä¸º text2vec åœ¨è®­ç»ƒçš„æ—¶å€™æ²¡æœ‰ä½¿ç”¨è¿‡æ£€ç´¢ç›¸å…³çš„æ•°æ®é›†ï¼Œæ‰€ä»¥æ²¡æœ‰åŠæ³•å¾ˆå¥½çš„å®Œæˆæ£€ç´¢ä»»åŠ¡ä¹Ÿæ˜¯æ­£å¸¸çš„ã€‚

## ğŸ“‚ M3Eæ•°æ®é›†

å¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨è¿™äº›æ•°æ®é›†ï¼Œä½ å¯ä»¥åœ¨ [uniem process_zh_datasets](https://github.com/wangyuxinwhy/uniem/blob/main/scripts/process_zh_datasets.py) ä¸­æ‰¾åˆ°åŠ è½½ huggingface æ•°æ®é›†çš„è„šæœ¬ï¼Œé huggingface æ•°æ®é›†éœ€è¦æ‚¨æ ¹æ®ä¸‹æ–¹æä¾›çš„é“¾æ¥è‡ªè¡Œä¸‹è½½å’Œå¤„ç†ã€‚

| æ•°æ®é›†åç§°           | é¢†åŸŸ | æ•°é‡      | ä»»åŠ¡ç±»å‹          | Prompt | è´¨é‡ | æ•°æ®æä¾›è€…                                                   | è¯´æ˜                                                         | æ˜¯å¦å¼€æº/ç ”ç©¶ä½¿ç”¨ | æ˜¯å¦å•†ç”¨ | è„šæœ¬ | Done | URL                                                          | æ˜¯å¦åŒè´¨ |
| -------------------- | ---- | --------- | ----------------- | ------ | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------- | -------- | ---- | ---- | ------------------------------------------------------------ | -------- |
| cmrc2018             | ç™¾ç§‘ | 14,363    | é—®ç­”              | é—®ç­”   | ä¼˜   | Yiming Cui, Ting Liu, Wanxiang Che, Li Xiao, Zhipeng Chen, Wentao Ma, Shijin Wang, Guoping Hu | https://github.com/ymcui/cmrc2018/blob/master/README_CN.md ä¸“å®¶æ ‡æ³¨çš„åŸºäºç»´åŸºç™¾ç§‘çš„ä¸­æ–‡é˜…è¯»ç†è§£æ•°æ®é›†ï¼Œå°†é—®é¢˜å’Œä¸Šä¸‹æ–‡è§†ä¸ºæ­£ä¾‹ | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/cmrc2018                     | å¦       |
| belle_2m             | ç™¾ç§‘ | 2,000,000 | æŒ‡ä»¤å¾®è°ƒ          | æ—      | ä¼˜   | LianjiaTech/BELLE                                            | belle çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œä½¿ç”¨ self instruct æ–¹æ³•åŸºäº gpt3.5 ç”Ÿæˆ | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/BelleGroup/train_2M_CN       | å¦       |
| firefily             | ç™¾ç§‘ | 1,649,399 | æŒ‡ä»¤å¾®è°ƒ          | æ—      | ä¼˜   | YeungNLP                                                     | Fireflyï¼ˆæµè¤ï¼‰ æ˜¯ä¸€ä¸ªå¼€æºçš„ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰åœ¨ä¸­æ–‡æ•°æ®é›†ä¸Šè¿›è¡Œè°ƒä¼˜ã€‚ä½¿ç”¨äº†è¯è¡¨è£å‰ªã€ZeROç­‰æŠ€æœ¯ï¼Œæœ‰æ•ˆé™ä½æ˜¾å­˜æ¶ˆè€—å’Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚ åœ¨è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ›´å°çš„æ¨¡å‹å‚æ•°é‡ï¼Œä»¥åŠæ›´å°‘çš„è®¡ç®—èµ„æºã€‚ | æœªè¯´æ˜            | æœªè¯´æ˜   | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M  | å¦       |
| alpaca_gpt4          | ç™¾ç§‘ | 48,818    | æŒ‡ä»¤å¾®è°ƒ          | æ—      | ä¼˜   | Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, Jianfeng Gao | æœ¬æ•°æ®é›†æ˜¯å‚è€ƒAlpacaæ–¹æ³•åŸºäºGPT4å¾—åˆ°çš„self-instructæ•°æ®ï¼Œçº¦5ä¸‡æ¡ã€‚ | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/shibing624/alpaca-zh         | å¦       |
| zhihu_kol            | ç™¾ç§‘ | 1,006,218 | é—®ç­”              | é—®ç­”   | ä¼˜   | wangrui6                                                     | çŸ¥ä¹é—®ç­”                                                     | æœªè¯´æ˜            | æœªè¯´æ˜   | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/wangrui6/Zhihu-KOL           | å¦       |
| hc3_chinese          | ç™¾ç§‘ | 39,781    | é—®ç­”              | é—®ç­”   | è‰¯   | Hello-SimpleAI                                               | é—®ç­”æ•°æ®ï¼ŒåŒ…æ‹¬äººå·¥å›ç­”å’Œ GPT å›ç­”                            | æ˜¯                | æœªè¯´æ˜   | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese   | å¦       |
| amazon_reviews_multi | ç”µå•† | 210,000   | é—®ç­” æ–‡æœ¬åˆ†ç±»     | æ‘˜è¦   | ä¼˜   | äºšé©¬é€Š                                                       | äºšé©¬é€Šäº§å“è¯„è®ºæ•°æ®é›†                                         | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/amazon_reviews_multi/viewer/zh/train?row=8 | å¦       |
| mlqa                 | ç™¾ç§‘ | 85,853    | é—®ç­”              | é—®ç­”   | è‰¯   | patrickvonplaten                                             | ä¸€ä¸ªç”¨äºè¯„ä¼°è·¨è¯­è¨€é—®ç­”æ€§èƒ½çš„åŸºå‡†æ•°æ®é›†                       | æ˜¯                | æœªè¯´æ˜   | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/mlqa/viewer/mlqa-translate-train.zh/train?p=2 | å¦       |
| xlsum                | æ–°é—» | 93,404    | æ‘˜è¦              | æ‘˜è¦   | è‰¯   | BUET CSE NLP Group                                           | BBCçš„ä¸“ä¸šæ³¨é‡Šæ–‡ç« æ‘˜è¦å¯¹                                      | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/csebuetnlp/xlsum/viewer/chinese_simplified/train?row=259 | å¦       |
| ocnli                | å£è¯­ | 17,726    | è‡ªç„¶è¯­è¨€æ¨ç†      | æ¨ç†   | è‰¯   | Thomas Wolf                                                  | è‡ªç„¶è¯­è¨€æ¨ç†æ•°æ®é›†                                           | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/clue/viewer/ocnli            | æ˜¯       |
| BQ                   | é‡‘è | 60,000    | æ–‡æœ¬åˆ†ç±»          | ç›¸ä¼¼   | è‰¯   | Intelligent Computing Research Center, Harbin Institute of Technology(Shenzhen) | http://icrc.hitsz.edu.cn/info/1037/1162.htm BQ è¯­æ–™åº“åŒ…å«æ¥è‡ªç½‘ä¸Šé“¶è¡Œè‡ªå®šä¹‰æœåŠ¡æ—¥å¿—çš„ 120ï¼Œ000 ä¸ªé—®é¢˜å¯¹ã€‚å®ƒåˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼š100ï¼Œ000 å¯¹ç”¨äºè®­ç»ƒï¼Œ10ï¼Œ000 å¯¹ç”¨äºéªŒè¯ï¼Œ10ï¼Œ000 å¯¹ç”¨äºæµ‹è¯•ã€‚ æ•°æ®æä¾›è€…ï¼š å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦ï¼ˆæ·±åœ³ï¼‰æ™ºèƒ½è®¡ç®—ç ”ç©¶ä¸­å¿ƒ | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/shibing624/nli_zh/viewer/BQ  | æ˜¯       |
| lcqmc                | å£è¯­ | 149,226   | æ–‡æœ¬åˆ†ç±»          | ç›¸ä¼¼   | è‰¯   | Ming Xu                                                      | å“ˆå·¥å¤§æ–‡æœ¬åŒ¹é…æ•°æ®é›†ï¼ŒLCQMC æ˜¯å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å›½é™…é¡¶ä¼š COLING2018 æ„å»ºçš„é—®é¢˜è¯­ä¹‰åŒ¹é…æ•°æ®é›†ï¼Œå…¶ç›®æ ‡æ˜¯åˆ¤æ–­ä¸¤ä¸ªé—®é¢˜çš„è¯­ä¹‰æ˜¯å¦ç›¸åŒ | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/shibing624/nli_zh/viewer/LCQMC/train | æ˜¯       |
| paws-x               | ç™¾ç§‘ | 23,576    | æ–‡æœ¬åˆ†ç±»          | ç›¸ä¼¼   | ä¼˜   | Bhavitvya Malik                                              | PAWS Wikiä¸­çš„ç¤ºä¾‹                                            | æ˜¯                | æ˜¯       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/paws-x/viewer/zh/train       | æ˜¯       |
| wiki_atomic_edit     | ç™¾ç§‘ | 1,213,780 | å¹³è¡Œè¯­ä¹‰          | ç›¸ä¼¼   | ä¼˜   | abhishek thakur                                              | åŸºäºä¸­æ–‡ç»´åŸºç™¾ç§‘çš„ç¼–è¾‘è®°å½•æ”¶é›†çš„æ•°æ®é›†                       | æœªè¯´æ˜            | æœªè¯´æ˜   | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/wiki_atomic_edits            | æ˜¯       |
| chatmed_consult      | åŒ»è¯ | 549,326   | é—®ç­”              | é—®ç­”   | ä¼˜   | Wei Zhu                                                      | çœŸå®ä¸–ç•Œçš„åŒ»å­¦ç›¸å…³çš„é—®é¢˜ï¼Œä½¿ç”¨ gpt3.5 è¿›è¡Œå›ç­”               | æ˜¯                | å¦       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/michaelwzhu/ChatMed_Consult_Dataset | å¦       |
| webqa                | ç™¾ç§‘ | 42,216    | é—®ç­”              | é—®ç­”   | ä¼˜   | suolyer                                                      | ç™¾åº¦äº2016å¹´å¼€æºçš„æ•°æ®é›†ï¼Œæ•°æ®æ¥è‡ªäºç™¾åº¦çŸ¥é“ï¼›æ ¼å¼ä¸ºä¸€ä¸ªé—®é¢˜å¤šç¯‡æ„æ€åŸºæœ¬ä¸€è‡´çš„æ–‡ç« ï¼Œåˆ†ä¸ºäººä¸ºæ ‡æ³¨ä»¥åŠæµè§ˆå™¨æ£€ç´¢ï¼›æ•°æ®æ•´ä½“è´¨é‡ä¸­ï¼Œå› ä¸ºæ··åˆäº†å¾ˆå¤šæ£€ç´¢è€Œæ¥çš„æ–‡ç«  | æ˜¯                | æœªè¯´æ˜   | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/suolyer/webqa/viewer/suolyer--webqa/train?p=3 | å¦       |
| dureader_robust      | ç™¾ç§‘ | 65,937    | æœºå™¨é˜…è¯»ç†è§£ é—®ç­” | é—®ç­”   | ä¼˜   | ç™¾åº¦                                                         | DuReader robustæ—¨åœ¨åˆ©ç”¨çœŸå®åº”ç”¨ä¸­çš„æ•°æ®æ ·æœ¬æ¥è¡¡é‡é˜…è¯»ç†è§£æ¨¡å‹çš„é²æ£’æ€§ï¼Œè¯„æµ‹æ¨¡å‹çš„è¿‡æ•æ„Ÿæ€§ã€è¿‡ç¨³å®šæ€§ä»¥åŠæ³›åŒ–èƒ½åŠ›ï¼Œæ˜¯é¦–ä¸ªä¸­æ–‡é˜…è¯»ç†è§£é²æ£’æ€§æ•°æ®é›†ã€‚ | æ˜¯                | æ˜¯       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/PaddlePaddle/dureader_robust/viewer/plain_text/train?row=96 | å¦       |
| csl                  | å­¦æœ¯ | 395,927   | è¯­æ–™              | æ‘˜è¦   | ä¼˜   | Yudong Li, Yuqing Zhang, Zhe Zhao, Linlin Shen, Weijie Liu, Weiquan Mao and Hui Zhang | æä¾›é¦–ä¸ªä¸­æ–‡ç§‘å­¦æ–‡çŒ®æ•°æ®é›†ï¼ˆCSLï¼‰ï¼ŒåŒ…å« 396,209 ç¯‡ä¸­æ–‡æ ¸å¿ƒæœŸåˆŠè®ºæ–‡å…ƒä¿¡æ¯ ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ã€å…³é”®è¯ã€å­¦ç§‘ã€é—¨ç±»ï¼‰ã€‚CSL æ•°æ®é›†å¯ä»¥ä½œä¸ºé¢„è®­ç»ƒè¯­æ–™ï¼Œä¹Ÿå¯ä»¥æ„å»ºè®¸å¤šNLPä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬æ‘˜è¦ï¼ˆæ ‡é¢˜é¢„æµ‹ï¼‰ã€ å…³é”®è¯ç”Ÿæˆå’Œæ–‡æœ¬åˆ†ç±»ç­‰ã€‚ | æ˜¯                | æ˜¯       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/neuclir/csl                  | å¦       |
| miracl-corpus        | ç™¾ç§‘ | 4,934,368 | è¯­æ–™              | æ‘˜è¦   | ä¼˜   | MIRACL                                                       | The corpus for each language is prepared from a Wikipedia dump, where we keep only the plain text and discard images, tables, etc. Each article is segmented into multiple passages using WikiExtractor based on natural discourse units (e.g., \n\n in the wiki markup). Each of these passages comprises a "document" or unit of retrieval. We preserve the Wikipedia article title of each passage. | æ˜¯                | æ˜¯       | æ˜¯   | æ˜¯   | https://huggingface.co/datasets/miracl/miracl-corpus         | å¦       |
| lawzhidao            | æ³•å¾‹ | 36,368    | é—®ç­”              | é—®ç­”   | ä¼˜   | å’Œé²¸ç¤¾åŒº-Ustinian                                            | ç™¾åº¦çŸ¥é“æ¸…æ´—åçš„æ³•å¾‹é—®ç­”                                     | æ˜¯                | æ˜¯       | å¦   | æ˜¯   | https://www.heywhale.com/mw/dataset/5e953ca8e7ec38002d02fca7/content | å¦       |
| CINLID               | æˆè¯­ | 34,746    | å¹³è¡Œè¯­ä¹‰          | ç›¸ä¼¼   | ä¼˜   | é«˜é•¿å®½                                                       | ä¸­æ–‡æˆè¯­è¯­ä¹‰æ¨ç†æ•°æ®é›†ï¼ˆChinese Idioms Natural Language Inference Datasetï¼‰æ”¶é›†äº†106832æ¡ç”±äººå·¥æ’°å†™çš„æˆè¯­å¯¹ï¼ˆå«å°‘é‡æ­‡åè¯­ã€ä¿—è¯­ç­‰çŸ­æ–‡æœ¬ï¼‰ï¼Œé€šè¿‡äººå·¥æ ‡æ³¨çš„æ–¹å¼è¿›è¡Œå¹³è¡¡åˆ†ç±»ï¼Œæ ‡ç­¾ä¸ºentailmentã€contradictionå’Œneutralï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰çš„ä»»åŠ¡ã€‚ | æ˜¯                | å¦       | å¦   | æ˜¯   | https://www.luge.ai/#/luge/dataDetail?id=39                  | æ˜¯       |
| DuSQL                | SQL  | 25,003    | NL2SQL            | SQL    | ä¼˜   | ç™¾åº¦                                                         | DuSQLæ˜¯ä¸€ä¸ªé¢å‘å®é™…åº”ç”¨çš„æ•°æ®é›†ï¼ŒåŒ…å«200ä¸ªæ•°æ®åº“ï¼Œè¦†ç›–äº†164ä¸ªé¢†åŸŸï¼Œé—®é¢˜è¦†ç›–äº†åŒ¹é…ã€è®¡ç®—ã€æ¨ç†ç­‰å®é™…åº”ç”¨ä¸­å¸¸è§å½¢å¼ã€‚è¯¥æ•°æ®é›†æ›´è´´è¿‘çœŸå®åº”ç”¨åœºæ™¯ï¼Œè¦æ±‚æ¨¡å‹é¢†åŸŸæ— å…³ã€é—®é¢˜æ— å…³ï¼Œä¸”å…·å¤‡è®¡ç®—æ¨ç†ç­‰èƒ½åŠ›ã€‚ | æ˜¯                | å¦       | å¦   | æ˜¯   | https://www.luge.ai/#/luge/dataDetail?id=13                  | å¦       |
| Zhuiyi-NL2SQL        | SQL  | 45,918    | NL2SQL            | SQL    | ä¼˜   | è¿½ä¸€ç§‘æŠ€ åˆ˜äº‘å³°                                              | NL2SQLæ˜¯ä¸€ä¸ªå¤šé¢†åŸŸçš„ç®€å•æ•°æ®é›†ï¼Œå…¶ä¸»è¦åŒ…å«åŒ¹é…ç±»å‹é—®é¢˜ã€‚è¯¥æ•°æ®é›†ä¸»è¦éªŒè¯æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå…¶è¦æ±‚æ¨¡å‹å…·æœ‰è¾ƒå¼ºçš„é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€é—®é¢˜æ³›åŒ–èƒ½åŠ›ã€‚ | æ˜¯                | å¦       | å¦   | æ˜¯   | https://www.luge.ai/#/luge/dataDetail?id=12                  | å¦       |
| Cspider              | SQL  | 7,785     | NL2SQL            | SQL    | ä¼˜   | è¥¿æ¹–å¤§å­¦ å¼ å²³                                                | CSpideræ˜¯ä¸€ä¸ªå¤šè¯­è¨€æ•°æ®é›†ï¼Œå…¶é—®é¢˜ä»¥ä¸­æ–‡è¡¨è¾¾ï¼Œæ•°æ®åº“ä»¥è‹±æ–‡å­˜å‚¨ï¼Œè¿™ç§åŒè¯­æ¨¡å¼åœ¨å®é™…åº”ç”¨ä¸­ä¹Ÿéå¸¸å¸¸è§ï¼Œå°¤å…¶æ˜¯æ•°æ®åº“å¼•æ“å¯¹ä¸­æ–‡æ”¯æŒä¸å¥½çš„æƒ…å†µä¸‹ã€‚è¯¥æ•°æ®é›†è¦æ±‚æ¨¡å‹é¢†åŸŸæ— å…³ã€é—®é¢˜æ— å…³ï¼Œä¸”èƒ½å¤Ÿå®ç°å¤šè¯­è¨€åŒ¹é…ã€‚ | æ˜¯                | å¦       | å¦   | æ˜¯   | https://www.luge.ai/#/luge/dataDetail?id=11                  | å¦       |
| news2016zh           | æ–°é—» | 2,507,549 | è¯­æ–™              | æ‘˜è¦   | è‰¯   | Bright Xu                                                    | åŒ…å«äº†250ä¸‡ç¯‡æ–°é—»ã€‚æ–°é—»æ¥æºæ¶µç›–äº†6.3ä¸‡ä¸ªåª’ä½“ï¼Œå«æ ‡é¢˜ã€å…³é”®è¯ã€æè¿°ã€æ­£æ–‡ã€‚ | æ˜¯                | æ˜¯       | å¦   | æ˜¯   | https://github.com/brightmart/nlp_chinese_corpus             | å¦       |
| baike2018qa          | ç™¾ç§‘ | 1,470,142 | é—®ç­”              | é—®ç­”   | è‰¯   | Bright Xu                                                    | å«æœ‰150ä¸‡ä¸ªé¢„å…ˆè¿‡æ»¤è¿‡çš„ã€é«˜è´¨é‡é—®é¢˜å’Œç­”æ¡ˆï¼Œæ¯ä¸ªé—®é¢˜å±äºä¸€ä¸ªç±»åˆ«ã€‚æ€»å…±æœ‰492ä¸ªç±»åˆ«ï¼Œå…¶ä¸­é¢‘ç‡è¾¾åˆ°æˆ–è¶…è¿‡10æ¬¡çš„ç±»åˆ«æœ‰434ä¸ªã€‚ | æ˜¯                | æ˜¯       | å¦   | æ˜¯   | https://github.com/brightmart/nlp_chinese_corpus             | å¦       |
| webtext2019zh        | ç™¾ç§‘ | 4,258,310 | é—®ç­”              | é—®ç­”   | ä¼˜   | Bright Xu                                                    | å«æœ‰410ä¸‡ä¸ªé¢„å…ˆè¿‡æ»¤è¿‡çš„ã€é«˜è´¨é‡é—®é¢˜å’Œå›å¤ã€‚æ¯ä¸ªé—®é¢˜å±äºä¸€ä¸ªã€è¯é¢˜ã€‘ï¼Œæ€»å…±æœ‰2.8ä¸‡ä¸ªå„å¼è¯é¢˜ï¼Œè¯é¢˜åŒ…ç½—ä¸‡è±¡ã€‚ | æ˜¯                | æ˜¯       | å¦   | æ˜¯   | https://github.com/brightmart/nlp_chinese_corpus             | å¦       |
| SimCLUE              | ç™¾ç§‘ | 775,593   | å¹³è¡Œè¯­ä¹‰          | ç›¸ä¼¼   | è‰¯   | æ•°æ®é›†åˆï¼Œè¯·åœ¨ simCLUE ä¸­æŸ¥çœ‹                                | æ•´åˆäº†ä¸­æ–‡é¢†åŸŸç»å¤§å¤šæ•°å¯ç”¨çš„å¼€æºçš„è¯­ä¹‰ç›¸ä¼¼åº¦å’Œè‡ªç„¶è¯­è¨€æ¨ç†çš„æ•°æ®é›†ï¼Œå¹¶é‡æ–°åšäº†æ•°æ®æ‹†åˆ†å’Œæ•´ç†ã€‚ | æ˜¯                | å¦       | å¦   | æ˜¯   | https://github.com/CLUEbenchmark/SimCLUE                     | æ˜¯       |
| Chinese-SQuAD        | æ–°é—» | 76,449    | æœºå™¨é˜…è¯»ç†è§£      | é—®ç­”   | ä¼˜   | junzeng-pluto                                                | ä¸­æ–‡æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†ï¼Œé€šè¿‡æœºå™¨ç¿»è¯‘åŠ äººå·¥æ ¡æ­£çš„æ–¹å¼ä»åŸå§‹Squadè½¬æ¢è€Œæ¥ | æ˜¯                | å¦       | å¦   | æ˜¯   | https://github.com/pluto-junzeng/ChineseSquad                | å¦       |

## ğŸ—“ï¸ è®¡åˆ’è¡¨

- [x] å®Œæˆ MTEB ä¸­æ–‡è¯„æµ‹ BenchMark, [MTEB-zh](https://github.com/wangyuxinwhy/uniem/tree/main/mteb-zh)
- [x] å®Œæˆ Large æ¨¡å‹çš„è®­ç»ƒå’Œå¼€æº
- [x] å®Œæˆ Finetuner ï¼Œå…è®¸æ›´ä¼˜é›…çš„å¾®è°ƒ
- [ ] å¯¹ M3E æ•°æ®é›†è¿›è¡Œæ¸…æ´—ï¼Œä¿ç•™é«˜è´¨é‡çš„éƒ¨åˆ†ï¼Œç»„æˆ m3e-hqï¼Œå¹¶åœ¨ huggingface ä¸Šå¼€æº
- [ ] åœ¨ m3e-hq çš„æ•°æ®é›†ä¸Šè¡¥å…… hard negative çš„æ ·æœ¬åŠç›¸ä¼¼åº¦åˆ†æ•°ï¼Œç»„æˆ m3e-hq-with-scoreï¼Œå¹¶åœ¨ huggingface ä¸Šå¼€æº
- [ ] åœ¨ m3e-hq-with-score ä¸Šé€šè¿‡ [cosent loss](https://github.com/wangyuxinwhy/uniem/blob/main/uniem/criteria.py#LL24C39-L24C39) loss è¿›è¡Œè®­ç»ƒå¹¶å¼€æºæ¨¡å‹ï¼ŒCoSent åŸç†å‚è€ƒè¿™ç¯‡[åšå®¢](https://kexue.fm/archives/8847)
- [ ] å¼€æºå•†ç”¨ç‰ˆæœ¬çš„ M3E models

## ğŸ™ è‡´è°¢

æ„Ÿè°¢å¼€æºç¤¾åŒºæä¾›çš„ä¸­æ–‡è¯­æ–™ï¼Œæ„Ÿè°¢æ‰€æœ‰åœ¨æ­¤å·¥ä½œä¸­æä¾›å¸®åŠ©çš„äººä»¬ï¼Œå¸Œæœ›ä¸­æ–‡ç¤¾åŒºè¶Šæ¥è¶Šå¥½ï¼Œå…±å‹‰ï¼

## ğŸ“œ License

M3E models ä½¿ç”¨çš„æ•°æ®é›†ä¸­åŒ…æ‹¬å¤§é‡éå•†ç”¨çš„æ•°æ®é›†ï¼Œæ‰€ä»¥ M3E models ä¹Ÿæ˜¯éå•†ç”¨çš„ï¼Œä»…ä¾›ç ”ç©¶ä½¿ç”¨ã€‚ä¸è¿‡æˆ‘ä»¬å·²ç»åœ¨ M3E æ•°æ®é›†ä¸Šæ ‡è¯†äº†å•†ç”¨å’Œéå•†ç”¨çš„æ•°æ®é›†ï¼Œæ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚è‡ªè¡Œè®­ç»ƒã€‚

## Citation
Please cite this model using the following format:
```
  @software {Moka Massive Mixed Embedding,  
  author = {Wang Yuxin,Sun Qingxuan,He sicheng},  
  title = {M3E: Moka Massive Mixed Embedding Model},  
  year = {2023}
  }
```